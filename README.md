# Text_classification
Text classification based on sentiment analysis for Natural Languages Processing course
Sentiment analysis is a technique used in natural language processing to identify and extract subjective information from text data and determine the prevailing attitude of a particular text. 
This project aims to predict sentiments in Arabic reviews and assess the accuracy of different models. It involves data preparation, model training, and the use of advanced NLP techniques like BERT for sentiment analysis. Results are evaluated using metrics like confusion matrices and classification reports to determine the best-performing models.
1. Preprocessing: This stage involves preparing the data for analysis. Key preprocessing steps include unpacking texts to remove extra tags and symbols, tokenization to divide text into sentences and words, and formatting to analyze the sentiment and topic of the text.

2. BERT Model: The project utilizes the Bidirectional Encoder Representations from Transformers (BERT) model, a pre-trained deep learning model developed by Google AI. BERT has several advantages, including its ability to learn the relationship between words in a sentence, making it suitable for various natural language processing (NLP) tasks, including sentiment analysis.

3. Libraries: Several libraries are used in the project, including Numpy, Pandas, Seaborn, Transformers, Time, Unicodedata, Torch, Train_test_split, MultinomialNB, Classification_report, CountVectorizer, and matplotlib.pyplot. These libraries are employed for tasks such as data manipulation, visualization, machine learning, and text processing.

4. Model Training: After preprocessing the data, the project involves training the BERT model on the Arabic dataset, specifically for sentiment analysis of reviews. The accuracy of the model's predictions for negative and positive reviews is tested. Various machine learning models from the Sklearn library are also compared to evaluate performance.

   
After conducting sentiment analysis on an Arabic text using BERT, it can be concluded that the model performed well in accurately identifying and classifying the sentiment of the text. BERT's ability to understand the context and nuances of the language contributed to its high accuracy in sentiment analysis. The results showed that the trained model achieved an accuracy of 87.67% on the test data, indicating that the model learned reasonably well from the training data. Additionally, we compared the test model with other ML models such as Naive Bayes MultinomialNB and BernoulliNB, to evaluate accuracy in the sentiment prediction model. After applying NB models on the same Arabic dataset, we concluded that BERT had the best accuracy as it outperformed both MultinomialNB and BernoulliNB by approximately 5%. Overall, BERT proves to be a promising tool for sentiment analysis in Arabic texts. As the field of natural language processing continues to evolve, we can expect to see even more advanced techniques and models that will further enhance the accuracy and effectiveness of sentiment analysis for Arabic text.
